{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashyaks/compute_tasks/blob/main/Lab_5/Lab5.1_LogisticRegression_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from numpy import log,dot,e,shape\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "29N1QiLc943O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r84pSBzTWIRn"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "X,Y=make_classification(n_samples=100, n_features=4,n_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)"
      ],
      "metadata": {
        "id": "2IRNuGvxdo8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(X_tr):\n",
        "    for i in range(shape(X_tr)[1]):\n",
        "        X_tr[:,i] = (X_tr[:,i] - np.mean(X_tr[:,i]))/np.std(X_tr[:,i])\n"
      ],
      "metadata": {
        "id": "Q6ZWtFG19-TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "\n",
        "  def sigmoid(self,z):\n",
        "        sig = 1/(1+e**(-z))\n",
        "        return sig\n",
        "\n",
        "  def initialize(self,X):\n",
        "        weights = np.zeros((shape(X)[1]+1,1))\n",
        "        X = np.c_[np.ones((shape(X)[0],1)),X]\n",
        "        return weights,X\n",
        "\n",
        "  def fit(self,X,y,alpha=0.001,iter=400):\n",
        "        weights,X = self.initialize(X)\n",
        "        def cost(theta):\n",
        "            z = dot(X,theta)\n",
        "            cost0 = y.T.dot(log(self.sigmoid(z)))\n",
        "            cost1 = (1-y).T.dot(log(1-self.sigmoid(z)))\n",
        "            cost = -((cost1 + cost0))/len(y)\n",
        "            return cost\n",
        "        cost_list = np.zeros(iter,)\n",
        "        for i in range(iter):\n",
        "            weights = weights - alpha*dot(X.T,self.sigmoid(dot(X,weights))-np.reshape(y,(len(y),1)))\n",
        "            cost_list[i] = cost(weights)\n",
        "        self.weights = weights\n",
        "        return cost_list\n",
        "\n",
        "  def predict(self,X):\n",
        "        z = dot(self.initialize(X)[1],self.weights)\n",
        "        lis = []\n",
        "        for i in self.sigmoid(z):\n",
        "\n",
        "            if i>0.5:\n",
        "                lis.append(1)\n",
        "            else:\n",
        "                lis.append(0)\n",
        "        return lis\n",
        "\n",
        "standardize(X_train)\n",
        "standardize(X_test)\n",
        "Logi = LogisticRegression()\n",
        "model= Logi.fit(X_train,y_train)\n",
        "y_pred = Logi.predict(X_test)\n",
        "y_train = Logi.predict(X_train)"
      ],
      "metadata": {
        "id": "iZj8nPrY-DBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score(y,y_hat):\n",
        "    tp,tn,fp,fn = 0,0,0,0\n",
        "    for i in range(len(y)):\n",
        "        if y[i] == 1 and y_hat[i] == 1:\n",
        "            tp += 1\n",
        "        elif y[i] == 1 and y_hat[i] == 0:\n",
        "            fn += 1\n",
        "        elif y[i] == 0 and y_hat[i] == 1:\n",
        "            fp += 1\n",
        "        elif y[i] == 0 and y_hat[i] == 0:\n",
        "            tn += 1\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/(tp+fn)\n",
        "    f1_score = 2*precision*recall/(precision+recall)\n",
        "    return f1_score\n",
        "\n",
        "f1_score_tr = f1_score(y_train,y_train)\n",
        "f1_score_te = f1_score(y_test,y_pred)\n",
        "print(f1_score_tr)\n",
        "print(f1_score_te)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSqzkyZI-J7u",
        "outputId": "8f7e40fb-846b-436c-fdf2-638508c9ad7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "model = LogisticRegression().fit(X_train,y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f1_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRty8isFD6IO",
        "outputId": "d2ecbdb1-9bd5-4a20-917e-9257323179fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666666666666\n"
          ]
        }
      ]
    }
  ]
}